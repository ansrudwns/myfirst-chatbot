import streamlit as st
import os
import arxiv
from openai import AzureOpenAI
from dotenv import load_dotenv

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Paper Mate", page_icon="ğŸ“")
st.title("ğŸ“ Paper Mate: ë…¼ë¬¸ ê²€ìƒ‰ & ì¸ìš© ë„ìš°ë¯¸")
st.caption("ê´€ì‹¬ ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´ ArXivì—ì„œ ë…¼ë¬¸ì„ ì°¾ì•„ ìš”ì•½ ë° APA ì¸ìš©êµ¬ë¥¼ ìƒì„±í•´ ì¤ë‹ˆë‹¤.")

# 2. Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# .env íŒŒì¼ì— í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
client = AzureOpenAI(
    api_key=os.getenv("AZURE_OAI_KEY"),
    api_version="2024-05-01-preview",
    azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT")
)

# --- [í•µì‹¬ ê¸°ëŠ¥] ArXiv ë…¼ë¬¸ ê²€ìƒ‰ í•¨ìˆ˜ ---
def search_arxiv(query, max_results=3):
    """
    ArXivì—ì„œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  LLMì—ê²Œ ë„˜ê²¨ì¤„ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
    """
    # ê´€ë ¨ì„± ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê²€ìƒ‰
    search = arxiv.Search(
        query=query,
        max_results=max_results,
        sort_by=arxiv.SortCriterion.Relevance
    )
    
    results_text = []
    
    for result in search.results():
        # ì €ì ë¦¬ìŠ¤íŠ¸ ì •ë¦¬ (ìµœëŒ€ 3ëª…ê¹Œì§€ë§Œ í‘œì‹œí•˜ê³  et al. ì²˜ë¦¬ ë“±ì€ LLMì—ê²Œ ë§¡ê¹€)
        authors = ", ".join([author.name for author in result.authors])
        
        # ë°œí–‰ì¼ (ë…„ë„ ì¶”ì¶œìš©)
        published_year = result.published.strftime("%Y")
        
        # LLMì—ê²Œ ì „ë‹¬í•  êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸
        paper_data = f"""
        [Paper ID: {result.entry_id}]
        - Title: {result.title}
        - Authors: {authors}
        - Published Year: {published_year}
        - Abstract: {result.summary.replace(chr(10), " ")} 
        - PDF Link: {result.pdf_url}
        """
        results_text.append(paper_data)
    
    return "\n\n".join(results_text)

# 3. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ëŒ€í™” ê¸°ë¡ ìœ ì§€)
if "messages" not in st.session_state:
    st.session_state.messages = []
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: AIì˜ ì—­í• ì„ ì •ì˜í•©ë‹ˆë‹¤.
    st.session_state.messages.append({
        "role": "system",
        "content": """
        ë‹¹ì‹ ì€ ì—°êµ¬ìë“¤ì„ ë•ëŠ” 'ë…¼ë¬¸ ìš”ì•½ ë° ì¸ìš© ì „ë¬¸ê°€'ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìê°€ ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´ ê²€ìƒ‰ëœ ë…¼ë¬¸ ë°ì´í„°(Context)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ í˜•ì‹ì— ë§ì¶° ë‹µë³€í•˜ì„¸ìš”.
        
        --- ë‹µë³€ í˜•ì‹ ---
        
        ### 1. [ë…¼ë¬¸ ì œëª©] (ë°œí–‰ë…„ë„)
        * **í•µì‹¬ ìš”ì•½:** (Abstract ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ 3ë¬¸ì¥ ì´ë‚´ í•µì‹¬ ìš”ì•½)
        * **APA Citation:** (ì œê³µëœ ì €ì, ì—°ë„, ì œëª©ì„ ì‚¬ìš©í•˜ì—¬ ì™„ë²½í•œ APA ìŠ¤íƒ€ì¼ ì¸ìš©êµ¬ ì‘ì„±)
        * **PDF ë§í¬:** (ì œê³µëœ PDF Link URL í‘œì‹œ)
        
        --- (ì—¬ëŸ¬ ë…¼ë¬¸ì¼ ê²½ìš° ë°˜ë³µ) ---
        
        [ì£¼ì˜ì‚¬í•­]
        - ê²€ìƒ‰ëœ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì†”ì§í•˜ê²Œ ì—†ë‹¤ê³  ë§í•˜ì„¸ìš”.
        - APA ìŠ¤íƒ€ì¼ ì‘ì„± ì‹œ ì €ì ì´ë¦„ í‘œê¸°ë²•(Last, F. M.)ì„ ì •í™•íˆ ì§€í‚¤ì„¸ìš”.
        - ìš”ì•½ì€ ë°˜ë“œì‹œ 'í•œêµ­ì–´'ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        """
    })

# 4. í™”ë©´ì— ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
for message in st.session_state.messages:
    if message["role"] != "system": # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” í™”ë©´ì— ìˆ¨ê¹€
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# 5. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë…¼ë¬¸ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: RAG, Transformer, Quantum Computing)"):
    
    # (1) ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ í‘œì‹œ
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # (2) ë¡œë”© ë° ì²˜ë¦¬
    with st.spinner(f"ğŸ” '{prompt}' ê´€ë ¨ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            # ArXiv ê²€ìƒ‰ ìˆ˜í–‰
            search_context = search_arxiv(prompt)
            
            if not search_context:
                assistant_reply = "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œ(ì˜ì–´ ì¶”ì²œ)ë¡œ ë‹¤ì‹œ ì‹œë„í•´ ë³´ì„¸ìš”."
            else:
                # LLMì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€ êµ¬ì„± (ê²€ìƒ‰ ê²°ê³¼ + ì‚¬ìš©ì ì§ˆë¬¸)
                full_prompt = f"""
                ì‚¬ìš©ìê°€ '{prompt}'ì— ëŒ€í•œ ë…¼ë¬¸ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤.
                ì•„ë˜ ê²€ìƒ‰ëœ ë…¼ë¬¸ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì˜ í˜•ì‹ì— ë§ì¶° ë‹µë³€í•´ì£¼ì„¸ìš”.
                
                [ê²€ìƒ‰ëœ ë…¼ë¬¸ ë°ì´í„°]
                {search_context}
                """
                
                # ëŒ€í™” ë‚´ì—­ ë³µì‚¬ (ì‹œìŠ¤í…œ ë©”ì‹œì§€ í¬í•¨)
                messages_for_api = [
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages
                ]
                
                # ë§ˆì§€ë§‰ ë©”ì‹œì§€ëŠ” ê²€ìƒ‰ ë°ì´í„°ê°€ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸ë¡œ êµì²´ (ì‹¤ì œ API ì „ì†¡ìš©)
                # ì£¼ì˜: session_stateì—ëŠ” ì›ë³¸ ì§ˆë¬¸ë§Œ ì €ì¥í•˜ê³ , APIì—ëŠ” ë°ì´í„°ë¥¼ ì„ì–´ ë³´ëƒ…ë‹ˆë‹¤.
                messages_for_api.append({"role": "user", "content": full_prompt})

                # API í˜¸ì¶œ
                response = client.chat.completions.create(
                    model="gpt-4o-mini", # ë°°í¬ëª…(Deployment Name) í™•ì¸ í•„ìˆ˜!
                    messages=messages_for_api
                )
                assistant_reply = response.choices[0].message.content

            # (3) AI ì‘ë‹µ í™”ë©´ í‘œì‹œ
            with st.chat_message("assistant"):
                st.markdown(assistant_reply)

            # (4) ëŒ€í™” ê¸°ë¡ ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": assistant_reply})
            
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
